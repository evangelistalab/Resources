{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network(DNN) for data fitting\n",
    "### Shuhe Wang, Dec 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP1:\n",
    "pip install --upgrade pip\n",
    "#### STEP2:\n",
    "sudo pip install --no-cache-dir -I tensorflow==1.7     (If you have tensorflow installed)\n",
    "\n",
    "sudo pip install tensorflow==1.7                        (If you haven't installed it yet.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.contrib.framework.python.framework import checkpoint_utils as cu\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize global parameters here.\n",
    "\"\"\"\n",
    "    set size of data examples, how they are allocated to different sets and the training loop size\n",
    "\"\"\"\n",
    "### START CODE HERE ### \n",
    "num_examples = None\n",
    "validation_fraction = None\n",
    "test_fraction = None\n",
    "training_epochs = None\n",
    "### START CODE HERE ### \n",
    "\n",
    "\n",
    "PLOT_FIGURE = True\n",
    "figure_size = (16.0, 9.0)\n",
    "marker_size = 5.0\n",
    "neuron_of_layer = [1, 50, 50, 50, 50, 50, 50, 50, 1]\n",
    "beta = 0.01\n",
    "\n",
    "# The parameters below are automatically generated\n",
    "# !!! DO NOT CHANGE THEM !!!\n",
    "validation_set_size = int(num_examples*validation_fraction)\n",
    "test_set_size = int(num_examples*test_fraction)\n",
    "training_set_size = num_examples - validation_set_size - test_set_size\n",
    "training_epochs_digits = len(list(str(training_epochs)))\n",
    "display_step = int(training_epochs*0.1)\n",
    "num_of_all_layers = len(neuron_of_layer)\n",
    "num_of_hidden_layers = num_of_all_layers - 2\n",
    "\n",
    "assert type(num_examples)==int and num_examples>0\n",
    "assert training_set_size>0\n",
    "assert type(training_epochs)==int and training_epochs>10\n",
    "for i in neuron_of_layer:\n",
    "\tassert type(i)==int and i>0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "        DEFINE YOUR PREFERRED FUNCTIONS HERE (e.g. return np.cos(x))\n",
    "        MAKE SURE YOUR FUNCTION VALUE IS NOT SO LARGE FOR X IN (0, PI)\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ### \n",
    "    pass\n",
    "    ### END CODE HERE ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_x = np.random.uniform(0, np.pi, (1, num_examples)).T\n",
    "np.random.shuffle(all_x)\n",
    "\n",
    "\"\"\"\n",
    "    USE SLICING TO PARTITION SETS\n",
    "    YOU MAY USE VARIABLES : training_set_size, validation_set_size, test_set_size\n",
    "\"\"\"\n",
    "### START CODE HERE ### \n",
    "x_training, x_validation, x_test = (all_x[:None], \n",
    "                                    all_x[None: None],\n",
    "                                    all_x[None:])\n",
    "### START CODE HERE ### \n",
    "\n",
    "\"\"\"\n",
    "    USE f(X) TO GENERATE Y \n",
    "\"\"\"\n",
    "### START CODE HERE ### \n",
    "(y_training, y_validation, y_test) = (None)\n",
    "### END CODE HERE ### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(\"./figure\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "figure_path = os.getcwd() + '/figure'\n",
    "\n",
    "if PLOT_FIGURE:\n",
    "    fig = plt.figure(figsize=figure_size)\n",
    "    plt.scatter(x_training, y_training, c='r', label='training set', s=marker_size)\n",
    "    plt.scatter(x_validation, y_validation, c='b', label='validation set', s=marker_size)\n",
    "    plt.legend()\n",
    "    fig.savefig(os.path.join(figure_path, 'training_and_validation_sets.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set DNN training parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    RESET THE TF NETWORK GRAPH BEFORE INITIALIZATION \n",
    "\"\"\"\n",
    "### START CODE HERE ### \n",
    "\n",
    "### END CODE HERE ### \n",
    "\n",
    "### START CODE HERE ### \n",
    "(X, Y) = (tf.placeholder(tf.float32, [None, None], name='Input'),\n",
    "          tf.placeholder(tf.float32, [None, None], name='Output'))\n",
    "### END CODE HERE ###                         \n",
    "\n",
    "\"\"\"\n",
    "    CREATE WEIGHTS AND BIASES\n",
    "    USE: tf.Variable(), tf.random_normal(), tf.zeros()\n",
    "\"\"\"\n",
    "### START CODE HERE ### \n",
    "(weights, biases) = ({str(i): tf.Variable(None,\n",
    "                          name = 'w{:d}'.format(i)) for i in range(num_of_all_layers-1)},\n",
    "                     {str(i): tf.Variable(None, \n",
    "                          name = 'b{:d}'.format(i)) for i in range(num_of_all_layers-1)})\n",
    "### END CODE HERE ###  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    REPLACE 'NONE' WITH TF FUNCTIONS\n",
    "    USE: tf.add(), tf.matmul(), tf.nn.sigmoid()\n",
    "\"\"\"\n",
    "### START CODE HERE ### \n",
    "def DNN(input_data, num_of_hidden_layers):\n",
    "    def _build_hidden(num_of_hidden_layers):\n",
    "        current_layer = 0\n",
    "        output_current_layer = input_data[:]\n",
    "        while current_layer < num_of_hidden_layers:\n",
    "            Z = None(\n",
    "                    None(output_current_layer, weights['%d'%(current_layer)]),\n",
    "                    biases['%d'%(current_layer)]\n",
    "                )\n",
    "            output_current_layer = None(Z, name='layer%d'%(current_layer))\n",
    "            current_layer += 1\n",
    "        return str(current_layer), output_current_layer \n",
    "\n",
    "    next_layer, layer = _build_hidden(num_of_hidden_layers)  \n",
    "    output_NN = None(None(layer, weights[next_layer]), biases[next_layer])\n",
    "    return output_NN\n",
    "### END CODE HERE ###  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up loss and add regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = DNN(X, num_of_hidden_layers)\n",
    "cost = tf.reduce_mean(tf.square(output - Y))\n",
    "loss = tf.nn.l2_loss(output - Y)\n",
    "for key in weights:\n",
    "    loss += tf.nn.l2_loss(weights[key]) * beta\n",
    "for key in biases:\n",
    "    loss += tf.nn.l2_loss(biases[key]) * beta\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    INITIALIZE\n",
    "    USE: tf.InteractiveSession(), tf.global_variables_initializer(), sess.run()\n",
    "\"\"\"\n",
    "### START CODE HERE ### \n",
    "sess = None\n",
    "init = None\n",
    "None\n",
    "### END CODE HERE ###  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, training_epochs+1):\n",
    "    _, c = sess.run(\n",
    "        [optimizer, cost ],\n",
    "        feed_dict={X: x_training, Y: y_training}\n",
    "    )\n",
    "\n",
    "    mse = sess.run(tf.nn.l2_loss(output - y_validation), feed_dict={X: x_validation})\n",
    "    \n",
    "    if not epoch % display_step :\n",
    "        print('Epoch: %0*d\\tCost : %.6f'%(training_epochs_digits, epoch, c))\n",
    "        if PLOT_FIGURE:\n",
    "            fig = plt.figure(figsize=figure_size)\n",
    "            plt.scatter(x_validation, y_validation, color='b', label='validation set', s=marker_size)\n",
    "            plt.scatter(x_validation, sess.run(output, feed_dict={X: x_validation}),\n",
    "                        color='r', label='DNN prediction', s=marker_size) \n",
    "            plt.legend()         \n",
    "            fig.savefig(os.path.join(figure_path, '%*d_DNN_prediction.jpg'%(training_epochs_digits, epoch)))\n",
    "\n",
    "print('Epoch: %03d\\tMSE  : %.6f'%(epoch, c), 'Training complete!', sep='\\n')\n",
    "\n",
    "save_model_list = [weights[i] for i in weights] + [biases[i] for i in biases]\n",
    "saver = tf.train.Saver(save_model_list)\n",
    "saver.save(sess, './trained_model/trained_model.ckpt')\n",
    "\n",
    "plt.close('all')\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run your trained DNN now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "        DEFINE THE SIGMOID FUNCTION HERE\n",
    "        use np.exp() instead of math.exp() since x is a numpy array\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ### \n",
    "    pass\n",
    "    ### END CODE HERE ### \n",
    "\n",
    "\n",
    "def _DNN(input_data, num_of_hidden_layers):\n",
    "    def _build_hidden(num_of_hidden_layers):\n",
    "        current_layer = 0\n",
    "        output_current_layer = input_data[:]\n",
    "        while current_layer < num_of_hidden_layers:\n",
    "            Z = np.add(\n",
    "                    np.matmul(output_current_layer, _weights['%d'%(current_layer)]),\n",
    "                    _biases['%d'%(current_layer)]\n",
    "                )\n",
    "            output_current_layer = sigmoid(Z)\n",
    "            current_layer += 1\n",
    "        return str(current_layer), output_current_layer \n",
    "        \n",
    "    next_layer, layer = _build_hidden(num_of_hidden_layers)  \n",
    "    output_NN = np.add(np.matmul(layer, _weights[next_layer]), _biases[next_layer])\n",
    "    return output_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ckpt_reader = tf.train.load_checkpoint('./trained_model/')\n",
    "for model_element in cu.list_variables('./trained_model/'):\n",
    "    print(model_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(_weights, _biases) = ({str(i): _ckpt_reader.get_tensor('w{:d}'.format(i)) for i in range(num_of_all_layers - 1)}, \n",
    "                       {str(i): _ckpt_reader.get_tensor('b{:d}'.format(i)) for i in range(num_of_all_layers - 1)})\n",
    "\n",
    "_output = _DNN(x_test, num_of_hidden_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_fig = plt.figure(figsize = figure_size)\n",
    "plt.scatter(x_test, y_test, color='r', label='test set', s=marker_size)\n",
    "plt.scatter(x_test, _output, color='g', label='DNN prediction', s=marker_size)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You can uninstall TF now!\n",
    "\n",
    "#### STEP3:\n",
    "sudo pip uninstall tensorflow "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
